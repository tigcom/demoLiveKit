================================================================================
H∆Ø·ªöNG D·∫™N CH·∫†Y D·ª∞ √ÅN (B·∫ÆT ƒê·∫¶U T·ª™NG B∆Ø·ªöC)
================================================================================

Khi b·∫°n ƒë√£ c√†i ƒë·∫∑t xong t·∫•t c·∫£ (xem file setup_and_install.txt),
b·∫°n c√≥ th·ªÉ ch·∫°y d·ª± √°n b·∫±ng h∆∞·ªõng d·∫´n n√†y.

CH√öC B·∫†N TH√ÄNH C√îNG! üéâ


B∆Ø·ªöC CHU·∫®N B·ªä
================================================================================

B·∫°n c·∫ßn 3 c·ª≠a s·ªï PowerShell/Terminal ri√™ng bi·ªát.
H√£y ƒë√≥ng h·∫øt c·ª≠a s·ªï c≈©, r·ªìi m·ªü 3 c·ª≠a s·ªï m·ªõi.

G·ª£i √Ω ph√¢n chia:
  C·ª≠a s·ªï 1: Ch·∫°y Token Server (uvicorn)
  C·ª≠a s·ªï 2: Ch·∫°y Frontend (npm run dev)
  C·ª≠a s·ªï 3: Ch·∫°y Backend Agent (python agent.py)
  (T√πy ch·ªçn: m·ªü th√™m c·ª≠a s·ªï ƒë·ªÉ ch·∫°y test script ho·∫∑c ti·ªÅn t·∫£i m√¥ h√¨nh)


================================================================================

L∆ØU √ù V·ªÄ M√î H√åNH LLM (Transformers):
================================================================================

·ªû phi√™n b·∫£n n√†y, agent s·ª≠ d·ª•ng Hugging Face Transformers + PyTorch ƒë·ªÉ
ch·∫°y m√¥ h√¨nh LLM c·ª•c b·ªô (ho·∫∑c d√πng model ƒë√£ c√†i s·∫µn). B·∫°n kh√¥ng c·∫ßn m·ªôt
server ri√™ng nh∆∞ Ollama n·ªØa.

N·∫øu b·∫°n mu·ªën ti·ªÅn t·∫£i m·ªôt model nh·ªè ƒë·ªÉ th·ª≠ nghi·ªám:

```powershell
python -c "from transformers import pipeline; p=pipeline('text-generation', model='gpt2'); print(p('Hello', max_new_tokens=5))"
```

L·ªánh tr√™n s·∫Ω t·∫£i model `gpt2` n·∫øu ch∆∞a c√≥ v√† in ra k·∫øt qu·∫£ ng·∫Øn ƒë·ªÉ x√°c nh·∫≠n.


================================================================================
B∆Ø·ªöC 2: CH·∫†Y TOKEN SERVER
================================================================================

ƒê√¢y l√† m√°y ch·ªß c·∫•p v√© truy c·∫≠p cho frontend.

C·ª≠a s·ªï 2 - Command Prompt:
  
  B∆Ø·ªöC 2.1: V√†o th∆∞ m·ª•c backend
    cd d:\project\livekit\livekit-voice-demo\backend
  
  B∆Ø·ªöC 2.2: K√≠ch ho·∫°t virtual environment
    .venv\Scripts\activate
    
    N·∫øu th√†nh c√¥ng, b·∫°n s·∫Ω th·∫•y "(.venv)" ·ªü ƒë·∫ßu d√≤ng
  
  B∆Ø·ªöC 2.3: Ch·∫°y token server
    uvicorn token_server:app --host 0.0.0.0 --port 8000
    
    B·∫°n s·∫Ω th·∫•y d√≤ng:
      Uvicorn running on http://0.0.0.0:8000

KI·ªÇM TRA TOKEN SERVER:
  M·ªü tr√¨nh duy·ªát, truy c·∫≠p: http://localhost:8000/healthz
  B·∫°n s·∫Ω th·∫•y "OK" ho·∫∑c m·ªôt d√≤ng JSON ‚Üí Token Server OK


================================================================================

B∆Ø·ªöC 3: CH·∫†Y FRONTEND (TRANG WEB)
================================================================================

ƒê√¢y l√† trang web b·∫°n s·∫Ω d√πng ƒë·ªÉ n√≥i v·ªõi AI.

Trong c·ª≠a s·ªï Frontend:

```powershell
cd d:\project\livekit\livekit-voice-demo\frontend
npm run dev
```

B·∫°n s·∫Ω th·∫•y d√≤ng b√°o Local URL, v√≠ d·ª•: http://localhost:5173

KI·ªÇM TRA FRONTEND:
  1. M·ªü tr√¨nh duy·ªát, truy c·∫≠p: http://localhost:5173
  2. Nh·∫≠p Room: demo-room, Identity: user-1
  3. Nh·∫•n "Join Room" v√† ch·ªù k·∫øt n·ªëi

N·∫øu kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c:
  - Ki·ªÉm tra Token Server c√≥ ch·∫°y (B∆∞·ªõc 2)
  - Ki·ªÉm tra console tr√¨nh duy·ªát (F12 ‚Üí Console)


================================================================================
B∆Ø·ªöC 4: CH·∫†Y BACKEND AGENT
================================================================================

ƒê√¢y l√† b·ªô n√£o, s·∫Ω nh·∫≠n ti·∫øng n√≥i v√† tr·∫£ l·ªùi.

C·ª≠a s·ªï 2 ho·∫∑c 4 - Command Prompt:
  
  B∆Ø·ªöC 4.1: V√†o th∆∞ m·ª•c backend
    cd d:\project\livekit\livekit-voice-demo\backend
  
  B∆Ø·ªöC 4.2: K√≠ch ho·∫°t virtual environment (n·∫øu ch∆∞a c√≥)
    .venv\Scripts\activate
  
  B∆Ø·ªöC 4.3: Ch·∫°y agent (Local debug ho·∫∑c LiveKit)
    # Local debug (kh√¥ng c·∫ßn LiveKit) - thu·∫≠n ti·ªán ƒë·ªÉ ki·ªÉm th·ª≠ pipeline STT‚ÜíLLM‚ÜíTTS
    python agent.py --local-debug --sample ./sample.wav --output ./reply.wav

    # Ho·∫∑c k·∫øt n·ªëi th·∫≠t t·ªõi LiveKit (y√™u c·∫ßu LIVEKIT_* trong .env)
    python agent.py --livekit

    Khi ch·∫°y --local-debug, t·∫≠p l·ªánh s·∫Ω:
      - Transcribe sample.wav
      - G·ªçi LLM (transformers)
      - Sinh TTS v√† l∆∞u reply.wav

    Khi ch·∫°y --livekit, agent s·∫Ω k·∫øt n·ªëi t·ªõi LiveKit v√† x·ª≠ l√Ω audio th·ª±c th·ªùi gian.


================================================================================
B∆Ø·ªöC 5: KI·ªÇM TRA H·ªÜ TH·ªêNG
================================================================================

Khi t·∫•t c·∫£ c√°c ph·∫ßn ƒë·ªÅu ch·∫°y, h√£y ki·ªÉm tra:

C·ª≠a s·ªï 1 (Ollama):
  ‚úì "Listening on 127.0.0.1:11434"

C·ª≠a s·ªï 2 (Token Server):
  ‚úì "Application startup complete"

C·ª≠a s·ªï 3 (Frontend):
  ‚úì "Local:   http://localhost:5173/"

C·ª≠a s·ªï 4 (Agent):
  ‚úì "‚úì Connected to demo-room"
  ‚úì "‚úì Local participant: agent-1"
  ‚úì "üë§ Participant connected: user-1"

N·∫øu t·∫•t c·∫£ ƒë·ªÅu ‚úì, b·∫°n ƒë√£ chu·∫©n b·ªã xong!


================================================================================
B∆Ø·ªöC 6: TEST T√çNH NƒÇNG CH√çNH
================================================================================

TEST 1: KI·ªÇM TRA MICRO

  1. M·ªü http://localhost:5173 tr√™n tr√¨nh duy·ªát
  2. B·∫•m n√∫t "Join Room"
  3. Ch·ªù k·∫øt n·ªëi th√†nh c√¥ng
  4. M·ªü browser console (F12 ‚Üí Console)
  5. B·∫°n s·∫Ω th·∫•y log:
     "Connected to room: demo-room"

TEST 2: KI·ªÇM TRA AI NGHE ƒê∆Ø·ª¢C

  1. N√≥i g√¨ ƒë√≥ v√†o micro (v√≠ d·ª•: "Ch√†o")
  2. Nh√¨n v√†o c·ª≠a s·ªï Agent (b∆∞·ªõc 4)
  3. B·∫°n s·∫Ω th·∫•y:
     "üó£Ô∏è User said: Ch√†o"
     
  N·∫øu th·∫•y v·∫≠y, AI ƒë√£ nghe ƒë∆∞·ª£c ‚úì

TEST 3: KI·ªÇM TRA AI TRRESPONSE

  1. Ch·ªù AI x·ª≠ l√Ω (chuy·ªÉn th√†nh ch·ªØ, h·ªèi LLM, chuy·ªÉn th√†nh ti·∫øng n√≥i)
  2. Kho·∫£ng 3-10 gi√¢y, b·∫°n s·∫Ω th·∫•y trong c·ª≠a s·ªï Agent:
     "üí¨ Agent reply: Xin ch√†o! C√≥ g√¨ t√¥i gi√∫p b·∫°n?"
     
  N·∫øu th·∫•y v·∫≠y, AI ƒë√£ suy nghƒ© ƒë∆∞·ª£c ‚úì

TEST 4: KI·ªÇM TRA ƒê∆†N L·∫†I TI·∫æNG N√ìI

  1. Nghe loa m√°y t√≠nh
  2. B·∫°n s·∫Ω nghe ti·∫øng AI n√≥i l·∫°i c√¢u tr·∫£ l·ªùi
  3. B·∫°n s·∫Ω th·∫•y trong c·ª≠a s·ªï Agent:
     "‚úì Published audio track: agent-reply"
     
  N·∫øu nghe ƒë∆∞·ª£c, AI ƒë√£ ph√°t √¢m th√†nh c√¥ng ‚úì


================================================================================
B∆Ø·ªöC 7: D·ª™NG D·ª∞ √ÅN
================================================================================

Khi mu·ªën d·ª´ng, h√£y l√†m theo th·ª© t·ª± n√†y:

1. D·ª´ng Agent (C·ª≠a s·ªï 4):
   Nh·∫•n Ctrl + C
   
2. D·ª´ng Frontend (C·ª≠a s·ªï 3):
   Nh·∫•n Ctrl + C
   
3. D·ª´ng Token Server (C·ª≠a s·ªï 2):
   Nh·∫•n Ctrl + C
   
4. D·ª´ng Ollama (C·ª≠a s·ªï 1):
   Nh·∫•n Ctrl + C
   
5. ƒê√≥ng t·∫•t c·∫£ c·ª≠a s·ªï Command Prompt


================================================================================
V·∫§N ƒê·ªÄ PH·ªî BI·∫æN V√Ä C√ÅCH S·ª¨A
================================================================================

V·∫§N ƒê·ªÄ: "Port 8000 ƒë√£ b·ªã s·ª≠ d·ª•ng"
  Nguy√™n nh√¢n: Token server ƒëang ch·∫°y ho·∫∑c ch∆∞∆°ng tr√¨nh kh√°c d√πng c·ªïng n√†y
  S·ª≠a:
    - D·ª´ng token server c≈© (Ctrl + C)
    - Ho·∫∑c thay c·ªïng kh√°c: uvicorn token_server:app --port 8001

V·∫§N ƒê·ªÄ: "Module not found: livekit"
  Nguy√™n nh√¢n: Virtual environment ch∆∞a k√≠ch ho·∫°t ho·∫∑c ch∆∞a c√†i th∆∞ vi·ªán
  S·ª≠a:
    - Ch·∫Øc ch·∫Øn virtual environment ƒë√£ k√≠ch ho·∫°t (th·∫•y "(.venv)")
    - Ch·∫°y l·∫°i: pip install -r requirements.txt

V·∫§N ƒê·ªÄ: "LLM/Transformers l·ªói ho·∫∑c model ch∆∞a t·∫£i"
  Nguy√™n nh√¢n: transformers/torch ch∆∞a c√†i ho·∫∑c model ƒëang t·∫£i xu·ªëng
  S·ª≠a:
    - Ki·ªÉm tra virtualenv ƒë√£ activate v√† c√†i dependencies (xem setup_and_install.txt)
    - Ch·∫°y l·ªánh ti·ªÅn t·∫£i model ƒë·ªÉ xem l·ªói: python -c "from transformers import pipeline; p=pipeline('text-generation', model='gpt2')"
    - N·∫øu thi·∫øu torch, c√†i torch theo B∆Ø·ªöC 3 (CPU ho·∫∑c CUDA)

V·∫§N ƒê·ªÄ: "Agent kh√¥ng nh·∫≠n ti·∫øng n√≥i"
  Nguy√™n nh√¢n: Frontend ch∆∞a k·∫øt n·ªëi ho·∫∑c micro kh√¥ng ho·∫°t ƒë·ªông
  S·ª≠a:
    - Ki·ªÉm tra Frontend c√≥ "Connected" kh√¥ng
    - Ki·ªÉm tra micro m√°y t√≠nh c√≥ b·∫≠t kh√¥ng (Settings ‚Üí Sound)
    - F12 ‚Üí Console xem c√≥ l·ªói kh√¥ng

V·∫§N ƒê·ªÄ: "Trang web kh√¥ng t·∫£i"
  Nguy√™n nh√¢n: Frontend ch∆∞a ch·∫°y ho·∫∑c c·ªïng 5173 b·ªã chi·∫øm
  S·ª≠a:
    - Ch·∫Øc ch·∫Øn `npm run dev` ƒëang ch·∫°y (B∆∞·ªõc 3)
    - Ki·ªÉm tra log c√≥ "Local: http://localhost:5173" kh√¥ng

V·∫§N ƒê·ªÄ: "AI kh√¥ng tr·∫£ l·ªùi"
  Nguy√™n nh√¢n: LLM ch∆∞a ch·∫°y ho·∫∑c model ch∆∞a t·∫£i
  S·ª≠a:
    - Ch·∫Øc ch·∫Øn Ollama ƒëang ch·∫°y
    - Ch·∫°y: ollama pull llama3
    - Ch·ªù model t·∫£i xong (~5-10 ph√∫t)


================================================================================
T√ìMO QUY TR√åNH CH·∫†YD·ª∞ √ÅN
================================================================================

L·∫¶N ƒê·∫¶U:
  1. uvicorn token_server:app --port 8000 (c·ª≠a s·ªï 1)
  2. npm run dev (c·ª≠a s·ªï 2)
  3. python agent.py --local-debug --sample sample.wav (c·ª≠a s·ªï 3)  # test nhanh
  4. (t√πy ch·ªçn) python agent.py --livekit  # ch·∫°y th·∫≠t cho LiveKit
  5. M·ªü http://localhost:5173
  6. N√≥i g√¨ ƒë√≥

L·∫¶N SAU:
  Ch·ªâ c·∫ßn ch·∫°y l·∫°i c√°c l·ªánh tr√™n (Ollama, Token Server, Frontend, Agent)

ƒê·ªÇ D·ª™NG:
  Nh·∫•n Ctrl + C tr√™n m·ªói c·ª≠a s·ªï (ng∆∞·ª£c th·ª© t·ª± c√†i)


================================================================================
TI·∫æP THEO
================================================================================

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ, h√£y xem file "troubleshooting.txt"
Mu·ªën hi·ªÉu r√µ h∆°n d·ª± √°n, xem file "overview.txt"
Mu·ªën bi·∫øt chi ti·∫øt t·ª´ng ph·∫ßn, xem file "components.txt"

================================================================================
